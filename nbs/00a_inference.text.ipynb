{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp inference.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text.inference\n",
    "\n",
    "> Provides inference scripts specifically for text modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.text.all import *\n",
    "from fastinference.inference.inference import _fully_decode, _decode_loss\n",
    "import matplotlib.cm as cm\n",
    "import html\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_preds(x:LMLearner, ds_idx=1, dl=None, raw_outs=False, decoded_loss=True, fully_decoded=False, concat_dim=0,\n",
    "             **kwargs):\n",
    "    \"Get predictions with possible decoding\"\n",
    "    inps, outs, dec_out, raw = [], [], [], []\n",
    "    if dl is None: dl = x.dls[ds_idx].new(shuffle=False, drop_last=False)\n",
    "    x.model.eval()\n",
    "    for batch in dl:\n",
    "        with torch.no_grad():\n",
    "            inps.append(batch[:x.dls.n_inp])\n",
    "            if decoded_loss or fully_decoded:\n",
    "                out = x.model(*batch[:x.dls.n_inp])[0]\n",
    "                raw.append(out)\n",
    "                dec_out.append(x.loss_func.decodes(out))\n",
    "            else:\n",
    "                raw.append(x.model(*batch[:x.dls.n_inp])[0])\n",
    "    raw = torch.cat(raw, dim=concat_dim).cpu().numpy()\n",
    "    if decoded_loss or fully_decoded:\n",
    "        dec_out = torch.cat(dec_out, dim=0)\n",
    "    if not raw_outs:\n",
    "        try: outs.insert(0, x.loss_func.activation(tensor(raw)).numpy())\n",
    "        except: outs.insert(0, dec_out)\n",
    "    else:\n",
    "        outs.insert(0, raw)\n",
    "    if fully_decoded: outs = _fully_decode(x.dls, inps, outs, dec_out, False)\n",
    "    if decoded_loss: outs = _decode_loss(x.dls.categorize.vocab, dec_out, outs)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LMLearner.get_preds\" class=\"doc_header\"><code>LMLearner.get_preds</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LMLearner.get_preds</code>(**`x`**:`LMLearner`, **`ds_idx`**=*`1`*, **`dl`**=*`None`*, **`raw_outs`**=*`False`*, **`decoded_loss`**=*`True`*, **`fully_decoded`**=*`False`*, **`concat_dim`**=*`0`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Get predictions with possible decoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LMLearner.get_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def get_preds(x:TextLearner, ds_idx=1, dl=None, raw_outs=False, decoded_loss=True, fully_decoded=False,\n",
    "             **kwargs):\n",
    "    \"Get predictions with possible decoding\"\n",
    "    inps, outs, dec_out, raw = [], [], [], []\n",
    "    if dl is None: dl = x.dls[ds_idx].new(shuffle=False, drop_last=False)\n",
    "    x.model.eval()\n",
    "    for batch in dl:\n",
    "        with torch.no_grad():\n",
    "            inps.append(batch[:x.dls.n_inp])\n",
    "            if decoded_loss or fully_decoded:\n",
    "                out = x.model(*batch[:x.dls.n_inp])[0]\n",
    "                raw.append(out)\n",
    "                dec_out.append(x.loss_func.decodes(out))\n",
    "            else:\n",
    "                raw.append(x.model(*batch[:x.dls.n_inp])[0])\n",
    "    raw = torch.cat(raw, dim=0).cpu().numpy()\n",
    "    if decoded_loss or fully_decoded:\n",
    "        dec_out = torch.cat(dec_out, dim=0)\n",
    "    if not raw_outs:\n",
    "        try: outs.insert(0, x.loss_func.activation(tensor(raw)).numpy())\n",
    "        except: outs.insert(0, dec_out)\n",
    "    else:\n",
    "        outs.insert(0, raw)\n",
    "    if fully_decoded: outs = _fully_decode(x.dls, inps, outs, dec_out, False)\n",
    "    if decoded_loss: outs = _decode_loss(x.dls.categorize.vocab, dec_out, outs)\n",
    "    return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"Learner.get_preds\" class=\"doc_header\"><code>Learner.get_preds</code><a href=\"https://github.com/muellerzr/fastinference/tree/master/fastinference/inference/inference.py#L39\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>Learner.get_preds</code>(**`x`**:`Learner`, **`ds_idx`**=*`1`*, **`dl`**=*`None`*, **`raw_outs`**=*`False`*, **`decoded_loss`**=*`True`*, **`fully_decoded`**=*`False`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Get predictions with possible decoding"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLearner.get_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def predict(x:LMLearner, text, n_words=1, no_unk=True, temperature=1., min_p=None, \n",
    "                decoder=decode_spec_tokens, only_last_word=False):\n",
    "        \"Predict `n_words` from `text`\"\n",
    "        x.model.reset()\n",
    "        idxs = idxs_all = x.dls.test_dl([text]).items[0].to(x.dls.device)\n",
    "        unk_idx = x.dls.vocab.index(UNK)\n",
    "        for _ in (range(n_words)):\n",
    "            preds = x.get_preds(dl=[(idxs[None],)], decoded_loss=False)\n",
    "            res = preds[0][0][-1]\n",
    "            if no_unk: res[unk_idx] = 0.\n",
    "            if min_p is not None:\n",
    "                if (res >= min_p).float().sum() == 0:\n",
    "                    warn(f\"There is no item with probability >= {min_p}, try a lower value.\")\n",
    "                else: res[res < min_p] = 0.\n",
    "            if temperature != 1.: res.pow_(1 / temperature)\n",
    "            res = tensor(res)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            idxs = idxs_all = torch.cat([idxs_all, idxs.new([idx])])\n",
    "            if only_last_word: idxs = idxs[-1][None]\n",
    "        decoder=decode_spec_tokens\n",
    "        num = x.dls.train_ds.numericalize\n",
    "        tokens = [num.vocab[i] for i in idxs_all if num.vocab[i] not in [BOS, PAD]]\n",
    "        sep = x.dls.train_ds.tokenizer[-1].sep\n",
    "        return sep.join(decoder(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"LMLearner.predict\" class=\"doc_header\"><code>LMLearner.predict</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>LMLearner.predict</code>(**`x`**:`LMLearner`, **`text`**, **`n_words`**=*`1`*, **`no_unk`**=*`True`*, **`temperature`**=*`1.0`*, **`min_p`**=*`None`*, **`decoder`**=*`'decode_spec_tokens'`*, **`only_last_word`**=*`False`*)\n",
       "\n",
       "Predict `n_words` from `text`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(LMLearner.predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path = untar_data(URLs.IMDB_SAMPLE)\n",
    "df = pd.read_csv(path/'texts.csv')\n",
    "data_lm = TextDataLoaders.from_csv(path, 'texts.csv', text_col='text', is_lm=True)\n",
    "lm_learn = language_model_learner(data_lm, AWD_LSTM, drop_mult=0.3)\n",
    "lm_learn.save_encoder('fine_tuned')\n",
    "blocks = (TextBlock.from_df('text', seq_len=data_lm.seq_len, vocab=data_lm.vocab), CategoryBlock())\n",
    "imdb_clas = DataBlock(blocks=blocks,\n",
    "                      get_x=ColReader('text'),\n",
    "                      get_y=ColReader('label'),\n",
    "                      splitter=ColSplitter())\n",
    "dls = imdb_clas.dataloaders(df, bs=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'my name is not always'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lm_learn.predict('my name is', n_words=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)\n",
    "learn.path = path\n",
    "learn.load_encoder('fine_tuned');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl = learn.dls.test_dl(df.iloc[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, probs, full_dec = learn.get_preds(dl=dl, fully_decoded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['negative'], array([[0.5106333 , 0.48936665]], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#1) [(\"xxbos xxmaj un - xxunk - believable ! xxmaj meg xxmaj ryan does n't even look her usual xxunk lovable self in this , which normally makes me forgive her shallow xxunk acting xxunk . xxmaj hard to believe she was the producer on this dog . xxmaj plus xxmaj kevin xxmaj kline : what kind of suicide trip has his career been on ? xxmaj xxunk â€¦ xxmaj xxunk xxrep 3 ! xxmaj finally this was directed by the guy who did xxmaj big xxmaj xxunk ? xxmaj must be a replay of xxmaj jonestown - hollywood style . w xxrep 3 o xxrep 3 f !\", 'negative')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _value2rgba(x, cmap=cm.RdYlGn, alpha_mult=1.0):\n",
    "    \"Convert a value `x` from 0 to 1 (inclusive) to an RGBA tuple according to `cmap` times transparency `alpha_mult`.\"\n",
    "    c = cmap(x)\n",
    "    rgb = (np.array(c[:-1]) * 255).astype(int)\n",
    "    a = c[-1] * alpha_mult\n",
    "    return tuple(rgb.tolist() + [a])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _eval_dropouts(mod):\n",
    "        module_name =  mod.__class__.__name__\n",
    "        if 'Dropout' in module_name or 'BatchNorm' in module_name: mod.training = False\n",
    "        for module in mod.children(): _eval_dropouts(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _piece_attn_html(pieces, attns, sep=' ', **kwargs):\n",
    "    html_code,spans = ['<span style=\"font-family: monospace;\">'], []\n",
    "    for p, a in zip(pieces, attns):\n",
    "        p = html.escape(p)\n",
    "        c = str(_value2rgba(a, alpha_mult=0.5, **kwargs))\n",
    "        spans.append(f'<span title=\"{a:.3f}\" style=\"background-color: rgba{c};\">{p}</span>')\n",
    "    html_code.append(sep.join(spans))\n",
    "    html_code.append('</span>')\n",
    "    return ''.join(html_code)\n",
    "\n",
    "def _show_piece_attn(*args, **kwargs):\n",
    "    from IPython.display import display, HTML\n",
    "    display(HTML(_piece_attn_html(*args, **kwargs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def _intrinsic_attention(learn, text, class_id=None):\n",
    "    \"Calculate the intrinsic attention of the input w.r.t to an output `class_id`, or the classification given by the model if `None`.\"\n",
    "    learn.model.train()\n",
    "    _eval_dropouts(learn.model)\n",
    "    learn.model.zero_grad()\n",
    "    learn.model.reset()\n",
    "    dl = learn.dls.test_dl([text])\n",
    "    batch = next(iter(dl))[0]\n",
    "    emb = learn.model[0].module.encoder(batch).detach().requires_grad_(True)\n",
    "    lstm = learn.model[0].module(emb, True)\n",
    "    learn.model.eval()\n",
    "    cl = learn.model[1]((lstm, torch.zeros_like(batch).bool(),))[0].softmax(dim=-1)\n",
    "    if class_id is None: class_id = cl.argmax()\n",
    "    cl[0][class_id].backward()\n",
    "    attn = emb.squeeze().abs().sum(dim=-1)\n",
    "    attn /= attn.max()\n",
    "    tok, _ = learn.dls.decode_batch((*tuplify(batch), *tuplify(cl)))[0]\n",
    "    return tok, attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@patch\n",
    "def intrinsic_attention(x:TextLearner, text:str, class_id:int=None, **kwargs):\n",
    "    \"Shows the `intrinsic attention for `text`, optional `class_id`\"\n",
    "    if isinstance(x, LMLearner): raise Exception(\"Language models are not supported\")\n",
    "    text, attn = _intrinsic_attention(x, text, class_id)\n",
    "    return _show_piece_attn(text.split(), to_np(attn), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h4 id=\"TextLearner.intrinsic_attention\" class=\"doc_header\"><code>TextLearner.intrinsic_attention</code><a href=\"__main__.py#L2\" class=\"source_link\" style=\"float:right\">[source]</a></h4>\n",
       "\n",
       "> <code>TextLearner.intrinsic_attention</code>(**`x`**:`TextLearner`, **`text`**:`str`, **`class_id`**:`int`=*`None`*, **\\*\\*`kwargs`**)\n",
       "\n",
       "Shows the `intrinsic attention for `text`, optional `class_id`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_doc(TextLearner.intrinsic_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"font-family: monospace;\"><span title=\"1.000\" style=\"background-color: rgba(0, 104, 55, 0.5);\">xxbos</span> <span title=\"0.666\" style=\"background-color: rgba(183, 224, 117, 0.5);\">xxmaj</span> <span title=\"0.318\" style=\"background-color: rgba(253, 182, 104, 0.5);\">batman</span> <span title=\"0.551\" style=\"background-color: rgba(234, 246, 163, 0.5);\">is</span> <span title=\"0.463\" style=\"background-color: rgba(254, 243, 171, 0.5);\">rich</span></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.intrinsic_attention('Batman is rich')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
